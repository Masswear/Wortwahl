{
    "contents" : "\n#predict next word based on input\n\n\n\n# function to clean input. Returns a character vector with individual tokens.\n# Requires the presence of \n\nregex <- read.csv(\"data/clean/regex.csv\", sep = \";\", stringsAsFactors = FALSE)\nabbrev <- read.csv(\"data/clean/abbreviations.csv\", stringsAsFactors = FALSE)\ntwitter_ab <- read.csv(\"data/clean/twitter_abbreviations.csv\", stringsAsFactors = FALSE)\n\nprofanity <- readLines(\"data/clean/profanity.txt\")\nreplace <- readLines(\"data/clean/replace.txt\")\n\nload(\"data/lookup/dict.RData\")\nload(\"data/lookup/newdict.RData\")\nload(\"data/lookup/satzanfang.RData\")\nload(\"data/lookup/n2_matrix.RData\")\nload(\"data/lookup/n3_matrix.RData\")\nload(\"data/lookup/n4_matrix.RData\")\nload(\"data/lookup/n2.RData\")\nload(\"data/lookup/n3.RData\")\nload(\"data/lookup/n4.RData\")\n\n\n\nregex <- read.csv(\"data/clean/regex.csv\", sep = \";\", stringsAsFactors = FALSE)\nabbrev <- read.csv(\"data/clean/abbreviations.csv\", stringsAsFactors = FALSE)\ntwitter_ab <- read.csv(\"data/clean/twitter_abbreviations.csv\", stringsAsFactors = FALSE)\n\n\n\nclean_input <- function(x){\n        \n        \n        x <- toLower(x)\n        \n        # replace numbers, ranges etc. \n        x <- stri_replace_all_regex(x,\n                                    regex$pattern,\n                                    regex$replacement,\n                                    vectorize_all = FALSE)\n        \n        # replace common abbreviations\n        x <- stri_replace_all_fixed(x,\n                                    abbrev$pattern,\n                                    abbrev$replacement,\n                                    vectorize_all = FALSE)\n        \n        # replace twitter abbreviations\n        x <- stri_replace_all_fixed(x,\n                                    twitter_ab$pattern,\n                                    twitter_ab$replacement,\n                                    vectorize_all = FALSE)\n        \n        # tokenize input\n        token <- tokenize(x, what = \"word\",\n                          removeNumbers = FALSE,\n                          removeSeparators = TRUE,\n                          removeTwitter = TRUE,\n                          removePunct = TRUE)[[1]]\n        \n        # replace tokens not in dictionary\n        token[!(token %in% dict$match)] <- \"<unk>\"\n        \n        token\n}\n\n\n# function that returns n-gram from tokenized phrase\n\nngrammer <- function(x, n) {\n        \n        # collapse to ngram\n        phrase <- paste(tail(x, n), collapse = \" \")\n        \n        phrase\n        \n}\n\n\n\n# function to calculate stupid backoff score\nStupidBackoff <- function(alpha = 0.4, n4, n3, n2) {\n        \n        score = 0\n        \n        if (!is.na(n4)){\n                score <- n4\n        }\n        \n        if (!is.na(n3) & (alpha * n3) > score){\n                score <- alpha * n3\n                \n        }\n        \n        if (!is.na(n2) & (alpha * alpha * n2) > score){\n                score <- alpha * alpha * n2\n                \n        }\n        \n        score\n        \n}\n\n# function that returns next word and frequency\nnextword.stupid <- function(x, n) {\n        \n        # return ID of matched phrase\n        n4_ID <- n4[n4$match == ngrammer(x, 3)]$ID_match\n        \n        n3_ID <- n3[n3$match == ngrammer(x, 2)]$ID_match\n        \n        n2_ID <- n2[n2$match == ngrammer(x, 1)]$ID_match\n        \n        # extract predictions from sparse matrix\n        if (length(n4_ID != 0)) {\n                \n                n4_match <- data.table(summary(n4_matrix)) %>%\n                            filter(i == n4_ID) %>%\n                            select(j, x) %>%\n                            arrange(desc(x))\n                \n        } else n4_match <- data.table(j = integer(),\n                                      x = integer())\n                \n        if (length(n3_ID != 0)){\n                \n                n3_match <- data.table(summary(n3_matrix)) %>%\n                            filter(i == n3_ID) %>%\n                            select(j, x) %>%\n                            arrange(desc(x))\n                \n        } else { n3_match <- data.table(j = integer(),\n                                      x = integer())\n        }\n                \n        if (length(n2_ID != 0)) {\n                \n                n2_match <- data.table(summary(n2_matrix)) %>%\n                            filter(i == n2_ID) %>%\n                            select(j, x) %>%\n                            arrange(desc(x))\n        } else n2_match <- data.table(j = integer(),\n                                      x = integer())\n        \n        \n        # create data frame with all predictions\n        df <- merge(n4_match, n3_match, by = \"j\", all = TRUE)\n        colnames(df) <- c(\"j\", \"n4_freq\", \"n3_freq\")\n        df <- merge(df, n2_match, by = \"j\", all = TRUE)\n        colnames(df) <- c(\"pred\", \"n4_freq\", \"n3_freq\", \"n2_freq\")\n        \n#         n4_match <- arrange(n4[n4$match == ngrammer(x, 3)], desc(freq)) %>%\n#                 select(pred, freq) \n#         \n#         n3_match <- arrange(n3[n3$match == ngrammer(x, 2)], desc(freq)) %>%\n#                 select(pred, freq)\n#         \n#         n2_match <- arrange(n2[n2$match == ngrammer(x, 1)], desc(freq)) %>%\n#                 select(pred, freq)\n        \n#         df <- merge(n4_match, n3_match, by = \"pred\", all = TRUE)\n#         colnames(df) <- c(\"pred\", \"n4_freq\", \"n3_freq\")\n#         df <- merge(df, n2_match, by = \"pred\", all = TRUE)\n#         colnames(df) <- c(\"pred\", \"n4_freq\", \"n3_freq\", \"n2_freq\")\n        \n        # if no matches found, return df based on unigrams\n        if (nrow(df) == 0 ) { df ## here comes code to return top unigrams\n                \n        # apply stupid backoff algorithm to all prediction frequencies to calculate score\n        } else {\n                df$score <- mapply(StupidBackoff, n4=df$n4_freq, n3=df$n3_freq,\n                                   n2=df$n2_freq)\n                df <- df %>% arrange(desc(score))\n                \n                head(df, n) # return specified number of predictions\n                \n        }       \n        \n}\n\nnextword <- function(x, n) {\n        \n        # return ID of matched phrase\n        n4_ID <- n4[n4$match == ngrammer(x, 3)]$ID_match\n        \n        n3_ID <- n3[n3$match == ngrammer(x, 2)]$ID_match\n        \n        n2_ID <- n2[n2$match == ngrammer(x, 1)]$ID_match\n        \n        # extract predictions from sparse matrix\n        if (length(n4_ID != 0)) {\n                \n                n4_match <- data.table(summary(n4_matrix)) %>%\n                        filter(i == n4_ID) %>%\n                        select(j, x) %>%\n                        arrange(desc(x))\n                \n        } else n4_match <- data.table(j = integer(),\n                                      x = integer())\n        \n        if (length(n3_ID != 0)){\n                \n                n3_match <- data.table(summary(n3_matrix)) %>%\n                        filter(i == n3_ID) %>%\n                        select(j, x) %>%\n                        arrange(desc(x))\n                \n        } else { n3_match <- data.table(j = integer(),\n                                        x = integer())\n        }\n        \n        if (length(n2_ID != 0)) {\n                \n                n2_match <- data.table(summary(n2_matrix)) %>%\n                        filter(i == n2_ID) %>%\n                        select(j, x) %>%\n                        arrange(desc(x))\n        } else n2_match <- data.table(j = integer(),\n                                      x = integer())\n        \n        \n        # create data frame with all predictions\n        df <- merge(n4_match, n3_match, by = \"j\", all = TRUE)\n        colnames(df) <- c(\"j\", \"n4_freq\", \"n3_freq\")\n        df <- merge(df, n2_match, by = \"j\", all = TRUE)\n        colnames(df) <- c(\"pred\", \"n4_freq\", \"n3_freq\", \"n2_freq\")\n        \n        #         n4_match <- arrange(n4[n4$match == ngrammer(x, 3)], desc(freq)) %>%\n        #                 select(pred, freq) \n        #         \n        #         n3_match <- arrange(n3[n3$match == ngrammer(x, 2)], desc(freq)) %>%\n        #                 select(pred, freq)\n        #         \n        #         n2_match <- arrange(n2[n2$match == ngrammer(x, 1)], desc(freq)) %>%\n        #                 select(pred, freq)\n        \n        #         df <- merge(n4_match, n3_match, by = \"pred\", all = TRUE)\n        #         colnames(df) <- c(\"pred\", \"n4_freq\", \"n3_freq\")\n        #         df <- merge(df, n2_match, by = \"pred\", all = TRUE)\n        #         colnames(df) <- c(\"pred\", \"n4_freq\", \"n3_freq\", \"n2_freq\")\n        \n        # if no matches found, return df based on unigrams\n        if (nrow(df) == 0 ) { df ## here comes code to return top unigrams\n                \n                # apply stupid backoff algorithm to all prediction frequencies to calculate score\n        } else {df <- df %>% arrange(desc(n4_freq), desc(n3_freq), desc(n2_freq))\n                \n                head(df, n) # return specified number of predictions\n                \n        }       \n        \n}\n\n# function that returns next word\n\nwortwahl <- function(input, resultlist = 30, show = 10, alpha = 0.4) {\n        \n        require(dplyr)\n        \n        phrase <- clean_input(input)\n        \n        df <- nextword(phrase, n = resultlist)\n        \n        if (nrow(df) == 0) {\n                \n                head(satzanfang, show)       \n                \n        } else {\n\n        # filter out profanity and replacements\n        df <- cbind(newdict[newdict$ID %in% df$pred], n4_freq = df$n4_freq,\n                    n3_freq = df$n3_freq, n2_freq = df$n2_freq)\n        df <- df %>%\n                filter(!(pred %in% profanity)) %>%\n                filter(!(pred %in% replace))\n        \n        \n                if (nrow(df) == 0) {\n                \n                        head(satzanfang, show)\n                \n                }\n        \n                else head(df, show)\n        }\n        \n}\n\nwortwahl.stupid <- function(input, resultlist = 30, show = 10, alpha = 0.4) {\n        \n        require(dplyr)\n        \n        phrase <- clean_input(input)\n        \n        df <- nextword.stupid(phrase, n = resultlist)\n        \n        if (nrow(df) == 0) {\n                \n                head(satzanfang, show)       \n                \n        } else {\n                \n                # filter out profanity and replacements\n                df <- cbind(newdict[newdict$ID %in% df$pred], score= df$score)\n                df <- df %>%\n                        filter(!(pred %in% profanity)) %>%\n                        filter(!(pred %in% replace)) %>%\n                        select(pred, score)\n                \n                \n                if (nrow(df) == 0) {\n                        \n                        head(satzanfang, show)\n                        \n                }\n                \n                else head(df, show)\n        }\n        \n}\n\n",
    "created" : 1451735480997.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "33|27|67|0|\n72|28|79|0|\n107|35|181|0|\n183|28|254|0|\n258|70|289|0|\n291|77|322|0|\n",
    "hash" : "2776824764",
    "id" : "3C43092",
    "lastKnownWriteTime" : 1452960103,
    "path" : "~/Weiterbildungen/DataScience/Capstone/shiny/prediction.R",
    "project_path" : "prediction.R",
    "properties" : {
    },
    "relative_order" : 9,
    "source_on_save" : false,
    "type" : "r_source"
}